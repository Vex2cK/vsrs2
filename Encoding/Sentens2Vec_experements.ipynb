{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae3f6af800b42d3938bfdc9b8e4b241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vex\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06530aaf5bed497c83b755731fd87de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a514397e8a4b84b2a5ec2c55dd95a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f868e87a0f48359c86d5b6a1ff92da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1bf6657e2c4819a1009e12e9a248fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e772bd8196a4f409f2adac61f0a1c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b948b9a3da04518b22dbb6db77913c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1db692dc54249b5b6be64da8d04d1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7da92b8d6e4a3db150d62acea79ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5488b180d5664efc84e120b0c1ca332d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ecbea46c5947ffa2da17ffc9fd59a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cuda')\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea70a13ae5024ac68def80225ce09ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vex\\.cache\\huggingface\\hub\\models--intfloat--multilingual-e5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c73888dd894ebbb2aa43232a6a8346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/160k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0aaec06052487bbbe6b774406a0139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2b43445caf4027b0bb422547e4387a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0dd92df57a54c6aa12709a77c2cece7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8369c3b789564550932f743f0c21e3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce6208390264ed3b93be05e23244adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13d50e8e00849498acb3e59e309e219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfda16fb52a4303b279d59793596ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbd306ef5b64aae8639da08d2677edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1024)\n",
      "tensor([[1.0000, 0.8827, 0.7679],\n",
      "        [0.8827, 1.0000, 0.7607],\n",
      "        [0.7679, 0.7607, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large\", device='cuda')\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7720]])\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large\", device='cuda')\n",
    "\n",
    "sentence1 = \"I'm a cat.\"\n",
    "sentence2 = \"The weather is great today.\"\n",
    "\n",
    "embedding1 = model.encode(sentence1)\n",
    "embedding2 = model.encode(sentence2)\n",
    "\n",
    "similarities = model.similarity(embedding1, embedding2)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\n",
    "    \"intfloat/multilingual-e5-large\",\n",
    "    prompts={\n",
    "        \"classification\": \"Classify the following text: \",\n",
    "        \"retrieval\": \"Retrieve semantically similar text: \",\n",
    "        \"clustering\": \"Identify the topic or theme based on the text: \",\n",
    "    },\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Этот новый фильм такой крутой\n",
      " - The dog plays in the garden   : 0.0750\n",
      " - The new movie is so great     : 0.0414\n",
      " - A woman watches TV            : 0.0649\n",
      "Кот сидит на улице\n",
      " - The dog plays in the garden   : 0.0609\n",
      " - The new movie is so great     : -0.0104\n",
      " - A woman watches TV            : -0.0104\n",
      "Мужчина играет на гитера\n",
      " - The dog plays in the garden   : 0.0742\n",
      " - The new movie is so great     : 0.0407\n",
      " - A woman watches TV            : 0.0169\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device='cuda')\n",
    "\n",
    "sentences1 = [\n",
    "    \"Этот новый фильм такой крутой\",\n",
    "    \"Кот сидит на улице\",\n",
    "    \"Мужчина играет на гитера\",\n",
    "]\n",
    "\n",
    "# sentences2 = [\n",
    "#     \"Собака играет во дворе\",\n",
    "#     \"Этот новый фильм очень классный!\",\n",
    "#     \"Женщина смотрит телевизор\",\n",
    "# ]\n",
    "\n",
    "# sentences1 = [\n",
    "#     \"The new movie is awesome\",\n",
    "#     \"The cat sits outside\",\n",
    "#     \"A man is playing guitar\",\n",
    "# ]\n",
    "\n",
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"The new movie is so great\",\n",
    "    \"A woman watches TV\",\n",
    "]\n",
    "\n",
    "# Compute embeddings for both lists\n",
    "embeddings1 = model.encode(sentences1)\n",
    "embeddings2 = model.encode(sentences2)\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarities = model.similarity(embeddings1, embeddings2)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for idx_i, sentence1 in enumerate(sentences1):\n",
    "    print(sentence1)\n",
    "    for idx_j, sentence2 in enumerate(sentences2):\n",
    "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Этот новый фильм такой крутой\n",
      " - The dog plays in the garden   : 0.0844\n",
      " - The new movie is so great     : 0.8547\n",
      " - A woman watches TV            : 0.1805\n",
      "Кот сидит на улице\n",
      " - The dog plays in the garden   : 0.2527\n",
      " - The new movie is so great     : 0.0796\n",
      " - A woman watches TV            : 0.0538\n",
      "Мужчина играет на гитера\n",
      " - The dog plays in the garden   : 0.0519\n",
      " - The new movie is so great     : 0.0310\n",
      " - A woman watches TV            : -0.0426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\", device='cuda')\n",
    "\n",
    "sentences1 = [\n",
    "    \"Этот новый фильм такой крутой\",\n",
    "    \"Кот сидит на улице\",\n",
    "    \"Мужчина играет на гитера\",\n",
    "]\n",
    "\n",
    "# sentences2 = [\n",
    "#     \"Собака играет во дворе\",\n",
    "#     \"Этот новый фильм очень классный!\",\n",
    "#     \"Женщина смотрит телевизор\",\n",
    "# ]\n",
    "\n",
    "# sentences1 = [\n",
    "#     \"The new movie is awesome\",\n",
    "#     \"The cat sits outside\",\n",
    "#     \"A man is playing guitar\",\n",
    "# ]\n",
    "\n",
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"The new movie is so great\",\n",
    "    \"A woman watches TV\",\n",
    "]\n",
    "\n",
    "# Compute embeddings for both lists\n",
    "embeddings1 = model.encode(sentences1)\n",
    "embeddings2 = model.encode(sentences2)\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarities = model.similarity(embeddings1, embeddings2)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for idx_i, sentence1 in enumerate(sentences1):\n",
    "    print(sentence1)\n",
    "    for idx_j, sentence2 in enumerate(sentences2):\n",
    "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"paraphrase-multilingual-mpnet-base-v2\" хорошая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Супер быстрая кластеризация какая-то: https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/clustering/fast_clustering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab32bdd3bf124f648e50dfda70c78af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vex\\.cache\\huggingface\\hub\\models--sentence-transformers--clip-ViT-B-32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe21342acfd4650af10522f1191d6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177dacf92b2c4eb3a222c9994a85fed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee17ad2727140ff833c439025f318ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/config.json:   0%|          | 0.00/4.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22ae7d7d5ac4696b5ad9039c0fdbdec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875b141845a94d9989adbfe58a5bffd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/tokenizer_config.json:   0%|          | 0.00/604 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307f95b567a643389f54bdfaaf089848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95300169f1a44308ba4f5cf67c2a5040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44f2b5a9b75490a8af7351a4a08b9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd50bb4376dd4b0f9cad035590522699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3027, 0.1073, 0.1149]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:491: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "\n",
    "# Load CLIP model\n",
    "model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "\n",
    "# Encode an image:\n",
    "img_emb = model.encode(Image.open(\"two_dogs_in_snow.jpg\"))\n",
    "\n",
    "# Encode text descriptions\n",
    "text_emb = model.encode(\n",
    "    [\"Two dogs in the snow\", \"A cat on a table\", \"A picture of London at night\"]\n",
    ")\n",
    "\n",
    "# Compute similarities\n",
    "similarity_scores = model.similarity(img_emb, text_emb)\n",
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вот это самая большая модель: 'clip-ViT-L-14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
