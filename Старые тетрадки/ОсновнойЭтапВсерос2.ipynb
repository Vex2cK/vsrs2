{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('train.csv')\n",
    "test_csv = pd.read_csv('test.csv')\n",
    "sample_sub_csv = pd.read_csv('sample_submission.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_by_substr(df, substr):\n",
    "    return [col for col in df.columns if substr in col]\n",
    "\n",
    "target = \"successful_utilization\"\n",
    "mb_cols = get_cols_by_substr(train_csv, 'mb')\n",
    "app_cols = get_cols_by_substr(train_csv, 'application')\n",
    "bki_cols = get_cols_by_substr(train_csv, 'bki')\n",
    "partner_cols = get_cols_by_substr(train_csv, 'partner')\n",
    "graph_cols = get_cols_by_substr(train_csv, 'graph')\n",
    "feature_cols = get_cols_by_substr(train_csv, 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv['cc_2'].fillna('missing', inplace=True)\n",
    "b = (train_csv['cc_2'].value_counts() / train_csv['cc_2'].shape[0]).reset_index()\n",
    "train_csv['cc_2_num'] = train_csv['cc_2'].apply(lambda x: b[b['cc_2'] == x]['count'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv['cc_4'].fillna('missing', inplace=True)\n",
    "b = (train_csv['cc_4'].value_counts() / train_csv['cc_4'].shape[0]).reset_index()\n",
    "train_csv['cc_4_num'] = train_csv['cc_4'].apply(lambda x: b[b['cc_4'] == x]['count'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv['cc_6'].fillna('missing', inplace=True)\n",
    "b = (train_csv['cc_6'].value_counts() / train_csv['cc_6'].shape[0]).reset_index()\n",
    "train_csv['cc_6_num'] = train_csv['cc_6'].apply(lambda x: b[b['cc_6'] == x]['count'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv['cc_2'].fillna('missing', inplace=True)\n",
    "b = (train_csv['cc_2'].value_counts() / train_csv['cc_2'].shape[0]).reset_index()\n",
    "test_csv['cc_2_num'] = test_csv['cc_2'].apply(lambda x: b[b['cc_2'] == x]['count'].values[0])\n",
    "\n",
    "test_csv['cc_4'].fillna('missing', inplace=True)\n",
    "b = (train_csv['cc_4'].value_counts() / train_csv['cc_4'].shape[0]).reset_index()\n",
    "test_csv['cc_4_num'] = test_csv['cc_4'].apply(lambda x: b[b['cc_4'] == x]['count'].values[0])\n",
    "\n",
    "test_csv['cc_6'].fillna('missing', inplace=True)\n",
    "b = (train_csv['cc_6'].value_counts() / train_csv['cc_6'].shape[0]).reset_index()\n",
    "test_csv['cc_6_num'] = test_csv['cc_6'].apply(lambda x: b[b['cc_6'] == x]['count'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_cols = list(set(get_cols_by_substr(train_csv, 'cc')) - {'cc_2', 'cc_4', 'cc_6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = list((set(mb_cols) | set(app_cols) | set(bki_cols) | set(partner_cols) | set(graph_cols) | set(feature_cols) | set(cc_cols) | {'treatment'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = ['cc_2', 'cc_4', 'cc_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe.fit(train_csv[obj_cols])\n",
    "\n",
    "train_df = train_csv[good_cols].copy(deep=True)\n",
    "test_df = test_csv[list(set(good_cols) - {'treatment', target})].copy(deep=True)\n",
    "\n",
    "train_df = pd.concat([train_df, pd.DataFrame(ohe.transform(train_csv[obj_cols]), columns=ohe.get_feature_names_out(obj_cols))], axis=1)\n",
    "test_df = pd.concat([test_df, pd.DataFrame(ohe.transform(test_csv[obj_cols]), columns=ohe.get_feature_names_out(obj_cols))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_df.isna().sum().sort_values(ascending=False)\n",
    "cols_with_na = list(a[a > 0].index)\n",
    "\n",
    "for col in cols_with_na:\n",
    "    na_count = train_df[col].isna().sum()\n",
    "    min_val = train_df[col].min()\n",
    "    if min_val >= 0:\n",
    "        train_df[col].fillna(-1, inplace=True)\n",
    "    else:\n",
    "        train_df[col].fillna(train_df[col].mean(), inplace=True)\n",
    "\n",
    "bin_cols = []\n",
    "\n",
    "train_df[\"cc_1\"] = train_df[\"cc_1\"].apply(lambda x: 1 if x == 1 else 0)\n",
    "train_df[\"feature_6\"] = train_df[\"feature_6\"].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].unique().size == 2:\n",
    "        bin_cols.append(col)\n",
    "\n",
    "\n",
    "\n",
    "for col in cols_with_na:\n",
    "    na_count = test_df[col].isna().sum()\n",
    "    min_val = test_df[col].min()\n",
    "    if min_val >= 0:\n",
    "        test_df[col].fillna(-1, inplace=True)\n",
    "    else:\n",
    "        test_df[col].fillna(test_df[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "test_df[\"cc_1\"] = test_df[\"cc_1\"].apply(lambda x: 1 if x == 1 else 0)\n",
    "test_df[\"feature_6\"] = train_df[\"feature_6\"].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Генерим фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols_without_target = list(set(good_cols) - {target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_0 = test_df.copy(deep=True)\n",
    "test_df_0['treatment'] = 0\n",
    "\n",
    "test_df_1 = test_df.copy(deep=True)\n",
    "test_df_1['treatment'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_extra_features = train_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(52)\n",
    "\n",
    "random.shuffle(good_cols_without_target)\n",
    "\n",
    "batches = [good_cols_without_target[i:i + 10] for i in range(0, len(good_cols_without_target), 10)]\n",
    "\n",
    "# for i, batch in enumerate(batches):\n",
    "#     print(f\"Batch {i + 1}: {len(batch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19aec7ea652441d4991aea1b0de9e421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i, batch in tqdm(enumerate(batches), total=15):\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    poly.fit(train_df[batch])\n",
    "\n",
    "    train_poly = poly.transform(train_df_extra_features[batch])\n",
    "    test_poly_0 = poly.transform(test_df_0[batch])\n",
    "    test_poly_1 = poly.transform(test_df_1[batch])\n",
    "\n",
    "    assert train_poly.shape[1] == test_poly_0.shape[1] == test_poly_1.shape[1]\n",
    "\n",
    "    col_names = poly.get_feature_names_out(batch)\n",
    "\n",
    "    train_df_extra_features.drop(columns=batch, inplace=True)\n",
    "    test_df_0.drop(columns=batch, inplace=True)\n",
    "    test_df_1.drop(columns=batch, inplace=True)\n",
    "\n",
    "    train_df_extra_features = pd.concat([train_df_extra_features, pd.DataFrame(train_poly, columns=col_names)], axis=1)\n",
    "    test_df_0 = pd.concat([test_df_0, pd.DataFrame(test_poly_0, columns=col_names)], axis=1)\n",
    "    test_df_1 = pd.concat([test_df_1, pd.DataFrame(test_poly_1, columns=col_names)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n = 5\n",
    "\n",
    "pca = PCA(n_components=n)\n",
    "X_train_pca = pca.fit_transform(train_df)\n",
    "\n",
    "pca = PCA(n_components=n)\n",
    "X_test_pca = pca.fit_transform(test_df)\n",
    "\n",
    "col_names_pca = [f'pca_{i}' for i in range(n)]\n",
    "\n",
    "train_df_extra_features = pd.concat([train_df_extra_features, pd.DataFrame(X_train_pca, columns=col_names_pca)], axis=1)\n",
    "test_df_0 = pd.concat([test_df_0, pd.DataFrame(X_test_pca, columns=col_names_pca)], axis=1)\n",
    "test_df_1 = pd.concat([test_df_1, pd.DataFrame(X_test_pca, columns=col_names_pca)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# inertia = []  # Список для хранения значений инерции\n",
    "# K = range(1, 7)  # Диапазон значений k (от 1 до 10)\n",
    "\n",
    "# for k in K:\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "#     kmeans.fit(train_df)\n",
    "#     inertia.append(kmeans.inertia_)  # Сохраняем инерцию для каждого k\n",
    "\n",
    "# # Шаг 2: Построение графика метода локтя\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(K, inertia, 'bo-', linewidth=2)\n",
    "# plt.xlabel('Количество кластеров k')\n",
    "# plt.ylabel('Инерция')\n",
    "# plt.title('Метод локтя для подбора k')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k = 2\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "kmeans.fit(train_df)\n",
    "\n",
    "# Получаем метки кластеров\n",
    "clusters_train = kmeans.labels_\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "kmeans.fit(test_df_0)\n",
    "\n",
    "clusters_test_0 = kmeans.labels_\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "kmeans.fit(test_df_1)\n",
    "\n",
    "clusters_test_1 = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_extra_features['cluster'] = clusters_train\n",
    "test_df_0['cluster'] = clusters_test_0\n",
    "test_df_1['cluster'] = clusters_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_log = list(set(good_cols_without_target) - (set(bin_cols)))\n",
    "new_log_cols = list(map(lambda x: f\"{x}_log\", cols_to_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\Vex\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n",
      "C:\\Users\\Vex\\AppData\\Local\\Temp\\ipykernel_16744\\2370510732.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))\n"
     ]
    }
   ],
   "source": [
    "train_df_extra_features[new_log_cols] = train_df_extra_features[cols_to_log].apply(lambda x: np.log(x + 1))\n",
    "test_df_0[new_log_cols] = test_df_0[cols_to_log].apply(lambda x: np.log(x + 1))\n",
    "test_df_1[new_log_cols] = test_df_1[cols_to_log].apply(lambda x: np.log(x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_sqrt = []\n",
    "\n",
    "for col in cols_to_log:\n",
    "    if train_df_extra_features[col].min() >= 0:\n",
    "        cols_to_sqrt.append(col)\n",
    "\n",
    "new_sqrt_cols = list(map(lambda x: x.replace('log', 'sqrt'), cols_to_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_extra_features[cols_to_sqrt] = train_df_extra_features[cols_to_sqrt].apply(lambda x: np.sqrt(x))\n",
    "test_df_0[cols_to_sqrt] = test_df_0[cols_to_sqrt].apply(lambda x: np.sqrt(x))\n",
    "test_df_1[cols_to_sqrt] = test_df_1[cols_to_sqrt].apply(lambda x: np.sqrt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_extra_features = train_df_extra_features.loc[:, ~train_df_extra_features.columns.duplicated()]\n",
    "test_df_0 = test_df_0.loc[:, ~test_df_0.columns.duplicated()]\n",
    "test_df_1 = test_df_1.loc[:, ~test_df_1.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "чистим оперативку xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "clusters_test_0 = 0\n",
    "clusters_test_1 = 0\n",
    "clusters = 0\n",
    "clusters_train = 0\n",
    "\n",
    "new_features = 0\n",
    "\n",
    "test_csv = 0\n",
    "train_csv = 0\n",
    "train_df = 0\n",
    "test_poly_0 = 0\n",
    "test_poly_1 = 0\n",
    "train_poly = 0\n",
    "\n",
    "X_train = 0\n",
    "\n",
    "kmeans = 0\n",
    "pca = 0\n",
    "poly = 0\n",
    "\n",
    "X_train_pca = 0\n",
    "X_test_pca = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_extra_features.to_csv(\"extra_train.csv\")\n",
    "test_df_0.to_csv(\"test_df_0.csv\")\n",
    "test_df_1.to_csv(\"test_df_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = train_df_extra_features.drop(columns=[target])\n",
    "y_train = train_df_extra_features[target]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_0 = test_df.copy(deep=True)\n",
    "# X_test_0['treatment'] = 0\n",
    "\n",
    "# X_test_1 = test_df.copy(deep=True)\n",
    "# X_test_1['treatment'] = 1\n",
    "\n",
    "# X_test_0 = X_test_0[X_train.columns]\n",
    "# X_test_1 = X_test_1[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.7351421505\n",
      "bestIteration = 438\n",
      "\n",
      "Shrink model to first 439 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1f086a6bc40>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=5,\n",
    "    learning_rate=0.133,\n",
    "    verbose=False,\n",
    "    eval_metric = 'AUC',\n",
    "    use_best_model=True,\n",
    "    auto_class_weights=\"SqrtBalanced\"\n",
    ")\n",
    "\n",
    "catboost_model.fit(X_train, y_train, eval_set=(X_val, y_val), logging_level='Verbose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cчитаем uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0 = catboost_model.predict_proba(test_df_0)[:,1]\n",
    "pred_1 = catboost_model.predict_proba(test_df_1)[:,1]\n",
    "super_cat_uplift = pred_1 - pred_0\n",
    "super_cat_uplift\n",
    "\n",
    "k += 1\n",
    "sample_sub_csv['successful_utilization'] = super_cat_uplift\n",
    "sample_sub_csv.to_csv(f'sub_gen_1_{k}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "усредняем всё что видим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['super_cat_mean_23_subs_uplift.csv', 'super_cat_mean_24_subs_uplift.csv']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir = 'mean_subs/'\n",
    "\n",
    "subs = os.listdir(dir)\n",
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(file_path):\n",
    "    return pd.read_csv(file_path).drop(columns=['Unnamed: 0'])['successful_utilization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = subs[0]\n",
    "\n",
    "sum = get_target(os.path.join(dir + sub1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subs[1:]:\n",
    "    sum += get_target(os.path.join(dir + sub))\n",
    "\n",
    "mean = sum / len(subs)\n",
    "\n",
    "i += 1\n",
    "sample_sub_csv['successful_utilization'] = mean\n",
    "sample_sub_csv.to_csv(f'super_cat_mean_{i}_subs_uplift.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
